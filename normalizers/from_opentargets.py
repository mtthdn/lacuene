#!/usr/bin/env python3
"""
Normalizer: Open Targets -> model/opentargets.cue

Queries the Open Targets Platform GraphQL API for each of the 95 neural crest
genes, extracting drug target status and known drug associations.

Ensembl gene IDs are resolved via the gnomAD cache (data/gnomad/gnomad_cache.json).

Results are cached in data/opentargets/opentargets_cache.json for reproducibility.

Usage:
    python3 normalizers/from_opentargets.py
"""

import json
import sys
import time
from pathlib import Path

# Resolve paths relative to repo root (parent of normalizers/)
REPO_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(REPO_ROOT / "normalizers"))

from genes import GENES
from pipeline import PipelineReport, escape_cue_string
from utils import post_json_with_retry

CACHE_DIR = REPO_ROOT / "data" / "opentargets"
CACHE_FILE = CACHE_DIR / "opentargets_cache.json"
OUTPUT_FILE = REPO_ROOT / "model" / "opentargets.cue"
GNOMAD_CACHE_FILE = REPO_ROOT / "data" / "gnomad" / "gnomad_cache.json"

OPENTARGETS_API_URL = "https://api.platform.opentargets.org/api/v4/graphql"

REQUEST_DELAY = 0.3  # seconds between requests

QUERY_TEMPLATE = """
query($ensemblId: String!) {
  target(ensemblId: $ensemblId) {
    id
    knownDrugs {
      count
      rows {
        drug {
          name
          drugType
        }
        phase
        disease {
          name
        }
      }
    }
  }
}
"""


def load_ensembl_ids() -> dict:
    """Load Ensembl gene IDs from gnomAD cache. Returns {symbol: ensembl_id}."""
    if not GNOMAD_CACHE_FILE.exists():
        print("  WARNING: gnomAD cache not found, cannot resolve Ensembl IDs", file=sys.stderr)
        return {}
    with open(GNOMAD_CACHE_FILE) as f:
        gnomad = json.load(f)
    mapping = {}
    for symbol, entry in gnomad.items():
        gene_id = entry.get("gene_id", "")
        if gene_id:
            mapping[symbol] = gene_id
    return mapping


def fetch_opentargets_gene(ensembl_id: str, symbol: str) -> dict | None:
    """
    Query Open Targets GraphQL API for an Ensembl gene ID. Returns dict with:
      - ensembl_id: Ensembl gene ID
      - drug_count: number of known drugs
      - max_phase: highest clinical trial phase
      - drugs: list of drug entries (top 5 by phase)
    Or None on failure.
    """
    try:
        data = post_json_with_retry(
            OPENTARGETS_API_URL,
            json_body={
                "query": QUERY_TEMPLATE,
                "variables": {"ensemblId": ensembl_id},
            },
            headers={"Accept": "application/json", "Content-Type": "application/json"},
        )
    except Exception as e:
        print(f"  WARNING: request failed for {symbol} ({ensembl_id}): {e}", file=sys.stderr)
        return None

    target = data.get("data", {}).get("target")
    if target is None:
        return None

    known_drugs = target.get("knownDrugs") or {}
    drug_count = known_drugs.get("count", 0)
    rows = known_drugs.get("rows") or []

    # Extract drug entries
    drugs = []
    for row in rows:
        drug_info = row.get("drug") or {}
        disease_info = row.get("disease") or {}
        drugs.append({
            "drug_name": drug_info.get("name", "Unknown"),
            "drug_type": drug_info.get("drugType", "Unknown"),
            "phase": row.get("phase", 0),
            "disease": disease_info.get("name", ""),
        })

    # Sort by phase descending, take top 5
    drugs.sort(key=lambda d: d["phase"], reverse=True)
    top_drugs = drugs[:5]

    max_phase = max((d["phase"] for d in drugs), default=0)

    return {
        "ensembl_id": ensembl_id,
        "drug_count": drug_count,
        "max_phase": max_phase,
        "drugs": top_drugs,
    }


def load_cache() -> dict:
    """Load cached Open Targets data if available."""
    if CACHE_FILE.exists():
        with open(CACHE_FILE) as f:
            return json.load(f)
    return {}


def save_cache(cache: dict) -> None:
    """Persist the Open Targets cache to disk."""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    with open(CACHE_FILE, "w") as f:
        json.dump(cache, f, indent=2, sort_keys=True)
    print(f"  cached: {CACHE_FILE}")


def generate_cue(opentargets_data: dict) -> str:
    """Generate CUE source from Open Targets data, keyed by HGNC symbol."""
    gene_count = len(opentargets_data)
    lines = [
        "package lacuene",
        "",
        "// Open Targets: drug target status for neural crest genes.",
        "// Source: Open Targets Platform GraphQL API",
        f"// Generated by normalizers/from_opentargets.py -- {gene_count} genes",
        "",
        "genes: {",
    ]

    for symbol in sorted(opentargets_data.keys()):
        entry = opentargets_data[symbol]
        ensembl_id = escape_cue_string(entry.get("ensembl_id", ""))
        drug_count = entry.get("drug_count", 0)
        max_phase = entry.get("max_phase", 0)
        drugs = entry.get("drugs", [])

        lines.append(f'\t"{symbol}": {{')
        lines.append(f"\t\t_in_opentargets: true")
        lines.append(f'\t\topentargets_id:  "{ensembl_id}"')

        if drug_count > 0:
            lines.append(f"\t\tis_drug_target:     true")
            lines.append(f"\t\tdrug_count:         {drug_count}")
            lines.append(f"\t\tmax_clinical_phase: {max_phase}")
        else:
            lines.append(f"\t\tis_drug_target:     false")
            lines.append(f"\t\tdrug_count:         0")
            lines.append(f"\t\tmax_clinical_phase: 0")

        if drugs:
            lines.append(f"\t\topentargets_drugs: [")
            for drug in drugs:
                dname = escape_cue_string(drug.get("drug_name", "Unknown"))
                dtype = escape_cue_string(drug.get("drug_type", "Unknown"))
                phase = drug.get("phase", 0)
                disease = escape_cue_string(drug.get("disease", ""))
                lines.append(f"\t\t\t{{")
                lines.append(f'\t\t\t\tdrug_name: "{dname}"')
                lines.append(f'\t\t\t\tdrug_type: "{dtype}"')
                lines.append(f"\t\t\t\tphase:     {phase}")
                if disease:
                    lines.append(f'\t\t\t\tdisease:   "{disease}"')
                lines.append(f"\t\t\t}},")
            lines.append(f"\t\t]")

        lines.append(f"\t}}")

    lines.append("}")
    lines.append("")  # trailing newline

    return "\n".join(lines)


def main():
    report = PipelineReport("from_opentargets")
    print("from_opentargets: querying Open Targets for neural crest gene drug targets...")

    # Load Ensembl ID mapping from gnomAD cache
    ensembl_map = load_ensembl_ids()
    if not ensembl_map:
        print("ERROR: no Ensembl ID mapping available (gnomAD cache missing)", file=sys.stderr)
        sys.exit(1)

    cache = load_cache()
    opentargets_data = {}
    fetched = 0
    cached_count = 0
    failed = 0
    skipped = 0

    for symbol in sorted(GENES.keys()):
        ensembl_id = ensembl_map.get(symbol)
        if not ensembl_id:
            print(f"  {symbol}: skipping (no Ensembl ID in gnomAD cache)")
            report.skipped(symbol, "no Ensembl ID")
            skipped += 1
            continue

        if symbol in cache:
            entry = cache[symbol]
            drug_count = entry.get("drug_count", 0)
            detail = f"{drug_count} drugs" if drug_count > 0 else "no drugs"
            print(f"  {symbol}: cached ({detail})")
            opentargets_data[symbol] = entry
            report.cached(symbol, detail)
            cached_count += 1
            continue

        print(f"  {symbol}: querying Open Targets...", end=" ", flush=True)
        result = fetch_opentargets_gene(ensembl_id, symbol)
        time.sleep(REQUEST_DELAY)

        if result is None:
            print(f"FAILED (skipping)", file=sys.stderr)
            report.failed(symbol, "API returned no data")
            failed += 1
            continue

        drug_count = result.get("drug_count", 0)
        max_phase = result.get("max_phase", 0)
        detail = f"{drug_count} drugs, max phase {max_phase}" if drug_count > 0 else "no drugs"
        print(detail)

        opentargets_data[symbol] = result
        cache[symbol] = result
        report.ok(symbol, detail)
        fetched += 1

    # Save updated cache
    save_cache(cache)

    if not opentargets_data:
        print("ERROR: no Open Targets data retrieved for any gene", file=sys.stderr)
        sys.exit(1)

    # Write CUE output
    print("from_opentargets: writing model/opentargets.cue...")
    cue_source = generate_cue(opentargets_data)
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, "w") as f:
        f.write(cue_source)

    # Stats
    has_drugs = sum(1 for d in opentargets_data.values() if d.get("drug_count", 0) > 0)

    print(f"from_opentargets: wrote {OUTPUT_FILE}")
    print(f"  {len(opentargets_data)} genes, {has_drugs} with drug targets")
    print(f"  ({fetched} fetched, {cached_count} cached, {failed} failed, {skipped} skipped)")
    print(report.summary())


if __name__ == "__main__":
    main()
